{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- forYaml_sampleobsbase.csv: missing key on \"Average black carbon load\"\n",
    "\n",
    "- implement labcutoff approach (based on calculation examples for all cases?)\n",
    "  - LOD/LOQ values\n",
    "\n",
    "- review formulas\n",
    "  - persistence strategy\n",
    "    - default reference values (comes with the formula)\n",
    "    - default calculation workflow(s) for an ObservableProperty\n",
    "    - study configuration / overrides for calculation & reference values\n",
    "    - calculation design persistence structure\n",
    "      - calculation_name\n",
    "      - calculation_implementation > e.g. point to named python function in hbm module\n",
    "      - calculation_implementation_as_string\n",
    "      - calculation_arguments > list of inputs: mapping name + type + expected unit + source/discovery path\n",
    "      - calculation_results > list of outputs: mapping name + type + expected unit + destination path\n",
    "      - conditionals: validity conditions (and/or check at input level)?\n",
    "  - implement python sum function, configure with input parameters and combine with imputation/normalisation functionality to handle current existing formulas?\n",
    "  - imp, meb (medium bound) > multiple cases to be persisted simultaneously?\n",
    "  - extensions: mol (core), lip/crt/sg (prop)\n",
    "\n",
    "- review indicators / varnames / constraints approach\n",
    "  - properties were previously defined at samplegroup level, indicators not necessarily\n",
    "  - Unit_keys preventing direct prop <> indicator conversion:\n",
    "    - Note: varname is unique at core level, prop has composite key: varname, samplegroup, unit \n",
    "    - find historical data solution for \"duplicated\" units: [\"ng/m²\", \"ng/filter\", \"pg BEQ/g\", \"pmol/g globin\"]\n",
    "  - anything to be handled with the historical \"tl\" situation?\n",
    "\n",
    "- review categorisation and links:\n",
    "  - Close_match > rather use the conceptual \"broader\"/\"narrower\" relations ?\n",
    "    - related: dd_core > relatedvarnames\n",
    "  - complete indicator_type list (exposuremarker, effectmarker, observation, ...) and ensure correct translation\n",
    "  - biochementity_links from effectmarkers, core <> prop, base <> core\n",
    "  - groupings from effectmarkers, base_category, core_category\n",
    "  - use calculated/measured sum and compound relations to deduce \"types\" of biochementities\n",
    "    - (compound, linear/branched/combination, measured/conceptual group, -deterministic- sum, metabolite, ...)\n",
    "\n",
    "- find non-biochementity indicators > change type to IndicatorType.observation + remove biochementity & links?\n",
    "- perclpfos-lpfos_perc: sampleobscore_key vs varname > sampleobscore_key is ignored\n",
    "- Statistics are per indicator with constraint > create indicator&property at detailed matrix level\n",
    "  - create new indicators for 2 'pg BEQ/g' blood items, 2 'pmol/g globin' blood items and 81 'ng/filter' air items\n",
    "  - create indicators for each of the entries in forYaml_sampleobsprop_statistics.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decimal\n",
    "import re\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from peh import BioChemEntity, Translation, BioChemEntityLink, BioChemEntityLinkType, BioChemIdentifier\n",
    "from peh import Indicator, IndicatorType, ObservableEntityType, QudtQuantityKind\n",
    "from peh import ObservableProperty, ObservablePropertyMetadataElement, ObservationType, ObservationResultType\n",
    "from peh import CalculationDesign, CalculationImplementation, CalculationArgument, CalculationKeywordArgument, CalculationResult\n",
    "from peh import ValidationDesign, ValidationStatus, ValidationHistoryRecord\n",
    "\n",
    "from linkml_runtime.dumpers import json_dumper, yaml_dumper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIT_CONVERSION = {\n",
    " '-': {\"property\": \"observation\", \"quantity_kind\": \"Dimensionless\", \"default_unit\": \"UNITLESS\"},\n",
    " 'mitochondrial/nuclear DNA': {\"property\": \"mitochondrial/nuclear DNA\", \"quantity_kind\": \"Dimensionless\", \"default_unit\": \"UNITLESS\"},\n",
    " 'number of cells': {\"property\": \"number of cells\", \"quantity_kind\": \"Dimensionless\", \"default_unit\": \"NUM\"},\n",
    "\n",
    " '%': {\"property\": \"percentage\", \"quantity_kind\": \"DimensionlessRatio\", \"default_unit\": \"PERCENT\"},\n",
    " '% (g/100g)': {\"property\": \"mass percentage\", \"quantity_kind\": \"DimensionlessRatio\", \"default_unit\": \"PERCENT\"},\n",
    " '% dm': {\"property\": \"percentage dry matter\", \"quantity_kind\": \"DimensionlessRatio\", \"default_unit\": \"PERCENT\"},\n",
    " 'index %': {\"property\": \"index percentage\", \"quantity_kind\": \"DimensionlessRatio\", \"default_unit\": \"PERCENT\"},\n",
    " 'ppb': {\"property\": \"parts per billion\", \"quantity_kind\": \"DimensionlessRatio\", \"default_unit\": \"PPB\"},\n",
    "\n",
    " 'ng/g': {\"property\": \"mass ratio\", \"quantity_kind\": \"DimensionlessRatio\", \"default_unit\": \"PPB\"},\n",
    " 'pg/mg': {\"property\": \"mass ratio\", \"quantity_kind\": \"DimensionlessRatio\", \"default_unit\": \"PPB\"},\n",
    " 'mg/kg': {\"property\": \"mass ratio\", \"quantity_kind\": \"DimensionlessRatio\", \"default_unit\": \"PPB\"},\n",
    " 'µg/kg dm': {\"property\": \"mass ratio dry matter\", \"quantity_kind\": \"DimensionlessRatio\", \"default_unit\": \"PPB\"},\n",
    " 'µg/kg ww': {\"property\": \"mass ratio wet weight\", \"quantity_kind\": \"DimensionlessRatio\", \"default_unit\": \"PPB\"},\n",
    " 'pg BEQ/g': {\"property\": \"bioanalytical equivalent mass ratio\", \"quantity_kind\": \"DimensionlessRatio\", \"default_unit\": \"PPTR\"},\n",
    " 'mmol/mol': {\"property\": \"amount of substance ratio\", \"quantity_kind\": \"DimensionlessRatio\", \"default_unit\": \"PPTH\"},\n",
    "\n",
    " 'pg': {\"property\": \"mass\", \"quantity_kind\": \"Mass\", \"default_unit\": \"PicoGM\"},\n",
    "\n",
    " 'L': {\"property\": \"volume\", \"quantity_kind\": \"Volume\", \"default_unit\": \"L\"},\n",
    " 'fL': {\"property\": \"volume\", \"quantity_kind\": \"Volume\", \"default_unit\": \"FemtoL\"},\n",
    "\n",
    " 'amount/µL': {\"property\": \"amount per volume\", \"quantity_kind\": \"NumberDensity\", \"default_unit\": \"NUM-PER-MicroL\"},\n",
    " 'milj/µL': {\"property\": \"amount per volume\", \"quantity_kind\": \"NumberDensity\", \"default_unit\": \"NUM-PER-PicoL\"},\n",
    " 'IU/L': {\"property\": \"amount per volume\", \"quantity_kind\": \"SerumOrPlasmaLevel\", \"default_unit\": \"IU-PER-L\"},\n",
    " 'kU/L': {\"property\": \"amount per volume\", \"quantity_kind\": \"SerumOrPlasmaLevel\", \"default_unit\": \"IU-PER-MilliL\"},\n",
    " 'µLU/mL': {\"property\": \"amount per volume\", \"quantity_kind\": \"SerumOrPlasmaLevel\", \"default_unit\": None},\n",
    "\n",
    " 'Osm/L': {\"property\": \"osmotic concentration\", \"quantity_kind\": \"AmountOfSubstanceConcentration\", \"default_unit\": \"MOL-PER-L\"},\n",
    "\n",
    " 'g/L': {\"property\": \"mass concentration\", \"quantity_kind\": \"MassConcentration\", \"default_unit\": \"MilliGM-PER-MilliL\"},\n",
    " 'g/dL': {\"property\": \"mass concentration\", \"quantity_kind\": \"MassConcentration\", \"default_unit\": \"GM-PER-DeciL\"},\n",
    " 'mg/L': {\"property\": \"mass concentration\", \"quantity_kind\": \"MassConcentration\", \"default_unit\": \"MilliGM-PER-L\"},\n",
    " 'mg/dL': {\"property\": \"mass concentration\", \"quantity_kind\": \"MassConcentration\", \"default_unit\": \"MilliGM-PER-DeciL\"},\n",
    " 'ng/L': {\"property\": \"mass concentration\", \"quantity_kind\": \"MassConcentration\", \"default_unit\": \"NanoGM-PER-L\"},\n",
    " 'ng/dL': {\"property\": \"mass concentration\", \"quantity_kind\": \"MassConcentration\", \"default_unit\": \"NanoGM-PER-DeciL\"},\n",
    " 'ng/mL': {\"property\": \"mass concentration\", \"quantity_kind\": \"MassConcentration\", \"default_unit\": \"NanoGM-PER-MilliL\"},\n",
    " 'pg/mL': {\"property\": \"mass concentration\", \"quantity_kind\": \"MassConcentration\", \"default_unit\": \"PicoGM-PER-MilliL\"},\n",
    " 'µg/L': {\"property\": \"mass concentration\", \"quantity_kind\": \"MassConcentration\", \"default_unit\": \"MicroGM-PER-L\"},\n",
    " 'µg/mL': {\"property\": \"mass concentration\", \"quantity_kind\": \"MassConcentration\", \"default_unit\": \"MicroGM-PER-MilliL\"},\n",
    " 'ng/m³': {\"property\": \"mass concentration\", \"quantity_kind\": \"MassConcentration\", \"default_unit\": \"NanoGM-PER-M3\"},\n",
    " \n",
    " 'ng/m²': {\"property\": \"mass per area\", \"quantity_kind\": \"MassPerArea\", \"default_unit\": \"NanoGM-PER-M2\"},\n",
    " \n",
    " 'nmol/L': {\"property\": \"substance concentration\", \"quantity_kind\": \"AmountOfSubstanceConcentration\", \"default_unit\": \"NanoMOL-PER-L\"},\n",
    " 'µmol/L': {\"property\": \"substance concentration\", \"quantity_kind\": \"AmountOfSubstanceConcentration\", \"default_unit\": \"MicroMOL-PER-L\"},\n",
    " \n",
    " 'pmol/g globin': {\"property\": \"substance per globin mass\", \"quantity_kind\": \"AmountOfSubstancePerUnitMass\", \"default_unit\": \"FemtoMOL-PER-KiloGM\"},\n",
    "\n",
    " 'ng/filter': {\"property\": \"mass per filter unit\", \"quantity_kind\": \"Mass\", \"default_unit\": \"GM\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def get_linktype(db_name):\n",
    "    translation_dict = {\n",
    "        \"branched version of\": BioChemEntityLinkType.branched_version_of,\n",
    "        \"parentcompound\": BioChemEntityLinkType.has_parent_compound,\n",
    "        \"parent compound\": BioChemEntityLinkType.has_parent_compound,\n",
    "        \"exact_match\": BioChemEntityLinkType.exact_match,\n",
    "        \"close_match\": BioChemEntityLinkType.close_match,\n",
    "    }\n",
    "    return translation_dict[db_name]\n",
    "\n",
    "def get_validation_status(db_name):\n",
    "    translation_dict = {\n",
    "        \"Validated\": ValidationStatus.validated,\n",
    "        \"Unvalidated\": ValidationStatus.unvalidated,\n",
    "        \"InProgress_Expert\": ValidationStatus.in_progress,\n",
    "        \"InProgress_Expert2nd\": ValidationStatus.in_progress,\n",
    "        \"InProgress_VITOInternal\": ValidationStatus.in_progress,\n",
    "    }\n",
    "    return translation_dict[db_name]\n",
    "\n",
    "def get_indicator_identifier(property, varname, matrix):\n",
    "    return f\"{property} of {varname} in {matrix}\"\n",
    "\n",
    "prop_translation_dict = {} # filled out later, reading data from on forYaml_sampleobscore_sampleobsprop.csv\n",
    "def get_indicator_identifier_from_sampleobsprop_id(sampleobsprop_id):\n",
    "    comp, matr, unit = prop_translation_dict[sampleobsprop_id].split(\"|\")\n",
    "    return get_indicator_identifier(UNIT_CONVERSION[unit][\"property\"], comp, matr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forYaml_sampleobsbase.csv\n",
    "df_base = pd.read_csv(\"../source_tables/indicator_input/forYaml_sampleobsbase.csv\", sep=';', encoding='utf-8')\n",
    "dl_base = df_base.replace({np.nan:None}).to_dict(orient=\"records\")\n",
    "dd_base = {e[\"sampleobsbase_key\"]:e for e in dl_base}\n",
    "base_translation_dict = {e[\"sampleobsbase_id\"]: e[\"sampleobsbase_key\"] for e in dl_base}\n",
    "print(\"[base keys]: \", \" - \".join(list(dd_base.values())[0].keys()))\n",
    "\n",
    "biochementity_dict = {\n",
    "    e[\"sampleobsbase_key\"]: BioChemEntity(\n",
    "        id = e[\"sampleobsbase_key\"],\n",
    "        unique_name = e[\"sampleobsbase_key\"],\n",
    "        name = e[\"name_en\"],\n",
    "        label = e[\"label_en\"],\n",
    "        molweight_grampermol = round(decimal.Decimal(e[\"molweight_grampermol\"]), 2) if e[\"molweight_grampermol\"] else None,\n",
    "        translations = [\n",
    "            Translation(property_name=\"name\", language=\"nl-be\", translated_value=e[\"name_nl\"]),\n",
    "            Translation(property_name=\"label\", language=\"nl-be\", translated_value=e[\"label_nl\"]),\n",
    "        ]\n",
    "    )\n",
    "    for e in dl_base\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forYaml_sampleobsbase_related.csv\n",
    "df_base_relations = pd.read_csv(\"../source_tables/indicator_input/forYaml_sampleobsbase_related.csv\", sep=';', encoding='utf-8')\n",
    "dl_base_relations = df_base_relations.replace({np.nan:None}).to_dict(orient=\"records\")\n",
    "dd_base_relations = {d:[br for br in dl_base_relations if br[\"sampleobsbase_id\"]==d] for d in set([r[\"sampleobsbase_id\"] for r in dl_base_relations])}\n",
    "\n",
    "for br in set([r[\"sampleobsbase_id\"] for r in dl_base_relations]):\n",
    "    rl = [r for r in dl_base_relations if r[\"sampleobsbase_id\"]==br]\n",
    "    biochementity_dict[base_translation_dict[br]].biochementity_links = [\n",
    "        BioChemEntityLink(biochementity_linktype=get_linktype(r[\"relation\"]), biochementity=biochementity_dict[base_translation_dict[r[\"sampleobsbase_relatedto_id\"]]].id) for r in rl\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forYaml_sampleobsbase_validation.csv\n",
    "df_base_validation = pd.read_csv(\"../source_tables/indicator_input/forYaml_sampleobsbase_validation.csv\", sep=';', encoding='utf-8')\n",
    "dl_base_validation = df_base_validation.replace({np.nan:None}).to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dl_base_validation duplications (should return empty list)\n",
    "unique_keys = list(set([v[\"sampleobsbase_key\"] for v in dl_base_validation]))\n",
    "base_validation_dict = {k:[bv for bv in dl_base_validation if bv[\"sampleobsbase_key\"]==k] for k in unique_keys}\n",
    "list(set([k for k in list(base_validation_dict.keys()) if len(base_validation_dict[k]) > 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check validation records without corresponding sampleobsbase records (should return empty list)\n",
    "[bv[\"sampleobsbase_key\"] for bv in dl_base_validation if bv[\"sampleobsbase_key\"] not in biochementity_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bv in [r for r in dl_base_validation if r[\"sampleobsbase_key\"] in biochementity_dict.keys()]:\n",
    "    biochementity_dict[bv[\"sampleobsbase_key\"]].current_validation_status = get_validation_status(bv[\"validationStatus\"])\n",
    "    biochementity_dict[bv[\"sampleobsbase_key\"]].validation_history = [\n",
    "        ValidationHistoryRecord(\n",
    "            validation_datetime=bv[\"validationDate\"],\n",
    "            validation_status=get_validation_status(bv[\"validationStatus\"]), validation_remark=bv[\"validationReference\"],\n",
    "            validation_actor=bv[\"validationEmail\"], validation_institute=bv[\"validationInstitute\"])\n",
    "    ]\n",
    "    if bv[\"validationStatus\"] == \"Validated\" and bv[\"validationID\"] == 'inchikey_id':\n",
    "        biochementity_dict[bv[\"sampleobsbase_key\"]].biochemidentifiers = [\n",
    "            BioChemIdentifier(identifier_schema=\"INCHIKEY\", identifier_code=bv[\"inchikey_id\"], validation_history=[\n",
    "                ValidationHistoryRecord(\n",
    "                    validation_datetime=bv[\"validationDate\"],\n",
    "                    validation_status=get_validation_status(bv[\"validationStatus\"]), validation_remark=bv[\"validationReference\"],\n",
    "                    validation_actor=bv[\"validationEmail\"], validation_institute=bv[\"validationInstitute\"])\n",
    "            ])\n",
    "        ]\n",
    "    if bv[\"validationStatus\"] == \"Validated\" and bv[\"validationID\"] == 'chebi_id':\n",
    "        biochementity_dict[bv[\"sampleobsbase_key\"]].biochemidentifiers = [\n",
    "            BioChemIdentifier(identifier_schema=\"CHEBI\", identifier_code=bv[\"chebi_id\"], validation_history=[\n",
    "                ValidationHistoryRecord(\n",
    "                    validation_datetime=bv[\"validationDate\"],\n",
    "                    validation_status=get_validation_status(bv[\"validationStatus\"]), validation_remark=bv[\"validationReference\"],\n",
    "                    validation_actor=bv[\"validationEmail\"], validation_institute=bv[\"validationInstitute\"])\n",
    "            ])\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique set of cores and full list of props from forYaml_sampleobscore_sampleobsprop.csv\n",
    "df_core_prop = pd.read_csv(\"../source_tables/indicator_input/forYaml_sampleobscore_sampleobsprop.csv\", sep=';', encoding='utf-8')\n",
    "dl_core_prop = df_core_prop.replace({np.nan:None}).to_dict(orient=\"records\")\n",
    "\n",
    "dl_core = [{k:v for k,v in [cp for cp in dl_core_prop if cp['sampleobscore_id']==i][0].items() if k in ['sampleobscore_id', 'sampleobscore_key', 'varname', 'sort', 'vartype_key', 'datatype_key', 'relatedvarnames',\n",
    "  'vartypedetail_key', 'label_en', 'name_en', 'label_nl', 'name_nl', '']} for i in set([ci[\"sampleobscore_id\"] for ci in dl_core_prop])]\n",
    "dd_core = {e[\"varname\"]:e for e in dl_core}\n",
    "core_translation_dict = {e[\"sampleobscore_id\"]: e[\"varname\"] for e in dl_core}\n",
    "print(\"[core keys]: \", \", \".join(list(dd_core.values())[0].keys()))\n",
    "print(\"datatype_key: \", \", \".join(set([c[\"datatype_key\"] for c in dl_core])))\n",
    "print(\"vartype_key: \", \", \".join(set([c[\"vartype_key\"] for c in dl_core])))\n",
    "print(\"vartypedetail_key: \", \", \".join(set([c[\"vartypedetail_key\"] for c in dl_core])))\n",
    "\n",
    "dl_prop = [{k:v for k,v in p.items() if k in [\"sampleobsprop_id\", \"sampleobscore_key\", \"varname\", \"samplegroup_key\", \"extensions\", \"unit_key\", \"significantdecimals\", \"zeroallowed\", \"formula\"]} for p in dl_core_prop]\n",
    "dd_prop = {\"|\".join([e[\"varname\"], e[\"samplegroup_key\"], e[\"unit_key\"]]):e for e in dl_prop}\n",
    "prop_translation_dict = {e[\"sampleobsprop_id\"]: \"|\".join([e[\"varname\"], e[\"samplegroup_key\"], e[\"unit_key\"]]) for e in dl_prop}\n",
    "print(\"[prop keys]: \", \", \".join(list(dd_prop.values())[0].keys()))\n",
    "print(\"samplegroup_key: \", \", \".join(sorted(set([c[\"samplegroup_key\"] for c in dl_prop]))))\n",
    "print(\"unit_key: \", \", \".join(sorted(set([c[\"unit_key\"] for c in dl_prop]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALCULATION_CONVERSION_DICT = {\n",
    "    e[\"formula\"].strip():{\"s\": e[\"formula\"].strip()} for e in dl_prop if e[\"formula\"]\n",
    "}\n",
    "\n",
    "def get_unit_from_formula(varname, formula):\n",
    "    if formula.startswith(varname + \" [\"):\n",
    "        unit_start = len(varname + \" [\")\n",
    "    elif formula.find(\" \" + varname + \" [\") >= 0:\n",
    "        unit_start = formula.find(\" \" + varname + \" [\") + len(\" \" + varname + \" [\")\n",
    "    else:\n",
    "        return None\n",
    "    unit_end = formula.find(\"]\", unit_start)\n",
    "    return formula[unit_start:unit_end]\n",
    "\n",
    "for c,d in CALCULATION_CONVERSION_DICT.items():\n",
    "    # special cases\n",
    "    if d[\"s\"].strip() == '(1 * trigl [mg/dL] ) + (2.27 * chol [mg/dL]) + 62.3':\n",
    "        d[\"complete\"] = True\n",
    "        d[\"function\"] = \"lipid_enz_harm\"\n",
    "        d[\"kwargs\"] = {\n",
    "            \"trigl\": {\n",
    "                \"varname\": \"trigl\",\n",
    "                \"unit\": \"\",\n",
    "                \"process_state\": \"imputed\"\n",
    "            },\n",
    "            \"chol\": {\n",
    "                \"varname\": \"chol\",\n",
    "                \"unit\": \"\",\n",
    "                \"process_state\": \"imputed\"\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        if d[\"s\"].startswith(\"round\"):\n",
    "            splitted_string = d[\"s\"].replace(\"(\", \"|\").replace(\",\", \"|\").replace(\")\", \"|\").split(\"|\")\n",
    "            if len(splitted_string) == 4:\n",
    "                d[\"round\"] = True\n",
    "                d[\"round_value\"] = int(splitted_string[2].strip())\n",
    "            else:\n",
    "                d[\"round\"] = True\n",
    "                d[\"round_value\"] = 0\n",
    "            d[\"s\"] = splitted_string[1].strip()\n",
    "        d[\"s_with_units\"] = d[\"s\"]\n",
    "        d[\"s\"] = re.sub(r'\\ \\[\\S+\\]', '', d[\"s\"])\n",
    "        if d[\"s\"].endswith(\"/100\"):\n",
    "            d[\"scale\"] = True\n",
    "            d[\"scale_value\"] = 0.01\n",
    "            d[\"s\"] = d[\"s\"][:-4].strip()\n",
    "        if d[\"s\"].endswith(\"/ 100\"):\n",
    "            d[\"scale\"] = True\n",
    "            d[\"scale_value\"] = 0.01\n",
    "            d[\"s\"] = d[\"s\"][:-5].strip()\n",
    "        if d[\"s\"].endswith(\"*100\"):\n",
    "            d[\"scale\"] = True\n",
    "            d[\"scale_value\"] = 100\n",
    "            d[\"s\"] = d[\"s\"][:-4].strip()\n",
    "        if d[\"s\"].endswith(\"* 100\"):\n",
    "            d[\"scale\"] = True\n",
    "            d[\"scale_value\"] = 100\n",
    "            d[\"s\"] = d[\"s\"][:-5].strip()\n",
    "        \n",
    "        d[\"complete\"] = False\n",
    "\n",
    "        # addition only\n",
    "        if \"-\" not in d[\"s\"] and \"/\" not in d[\"s\"] and \"*\" not in d[\"s\"]:\n",
    "            d[\"complete\"] = True\n",
    "            d[\"function\"] = \"addition\"\n",
    "            d[\"args\"] = [{\n",
    "                \"varname\": a.strip(),\n",
    "                \"unit\": get_unit_from_formula(a.strip(), d[\"s_with_units\"]),\n",
    "                \"process_state\": \"imputed\"\n",
    "            } for a in d[\"s\"].split(\"+\")]\n",
    "        # multiplication only\n",
    "        if \"-\" not in d[\"s\"] and \"+\" not in d[\"s\"] and \"/\" not in d[\"s\"]:\n",
    "            d[\"complete\"] = True\n",
    "            d[\"function\"] = \"multiplication\"\n",
    "            d[\"args\"] = [{\n",
    "                \"varname\": a.strip(),\n",
    "                \"unit\": get_unit_from_formula(a.strip(), d[\"s_with_units\"]),\n",
    "                \"process_state\": \"imputed\"\n",
    "            } for a in d[\"s\"].split(\"*\")]\n",
    "        # subtraction\n",
    "        if \"-\" in d[\"s\"] and len(d[\"s\"].split(\" \")) == 3 and len(d[\"s\"].split(\"-\")) == 2:\n",
    "            d[\"complete\"] = True\n",
    "            d[\"function\"] = \"subtraction\"\n",
    "            d[\"kwargs\"] = {\n",
    "                \"minuend\": {\n",
    "                    \"varname\": d[\"s\"].split(\"-\")[0].strip(),\n",
    "                    \"unit\": get_unit_from_formula(d[\"s\"].split(\"-\")[0].strip(), d[\"s_with_units\"]),\n",
    "                    \"process_state\": \"imputed\"\n",
    "                },\n",
    "                \"subtrahend\": {\n",
    "                    \"varname\": d[\"s\"].split(\"-\")[1].strip(),\n",
    "                    \"unit\": get_unit_from_formula(d[\"s\"].split(\"-\")[1].strip(), d[\"s_with_units\"]),\n",
    "                    \"process_state\": \"imputed\"\n",
    "                }\n",
    "            }\n",
    "        # division only\n",
    "        if \"/\" in d[\"s\"] and len(d[\"s\"].split(\" \")) == 3 and len(d[\"s\"].split(\"/\")) == 2:\n",
    "            d[\"complete\"] = True\n",
    "            d[\"function\"] = \"division\"\n",
    "            d[\"kwargs\"] = {\n",
    "                \"dividend\": {\n",
    "                    \"varname\": d[\"s\"].split(\"/\")[0].strip(),\n",
    "                    \"unit\": get_unit_from_formula(d[\"s\"].split(\"/\")[0].strip(), d[\"s_with_units\"]),\n",
    "                    \"process_state\": \"clean\"\n",
    "                },\n",
    "                \"divisor\": {\n",
    "                    \"varname\": d[\"s\"].split(\"/\")[1].strip(),\n",
    "                    \"unit\": get_unit_from_formula(d[\"s\"].split(\"/\")[1].strip(), d[\"s_with_units\"]),\n",
    "                    \"process_state\": \"clean\"\n",
    "                }\n",
    "            }\n",
    "\n",
    "def get_calculation_implementation_from_dict(d):\n",
    "    ci = CalculationImplementation(function_name=d['function'])\n",
    "    if \"args\" in d:\n",
    "        ci.function_args = [CalculationArgument(**a) for a in d[\"args\"]]\n",
    "    if \"kwargs\" in d:\n",
    "        ci.function_kwargs = [CalculationKeywordArgument(mapping_name=k, **a) for k,a in d[\"kwargs\"].items()]\n",
    "    fr = CalculationResult(value_type=\"decimal\")\n",
    "    if \"round\" in d and d[\"round\"]:\n",
    "        fr.round_decimals = d[\"round_value\"]\n",
    "    if \"scale\" in d and d[\"scale\"]:\n",
    "        fr.scale_factor = d[\"scale_value\"]\n",
    "    ci.function_results = [fr]\n",
    "    return ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_dict = {\n",
    "    get_indicator_identifier(UNIT_CONVERSION[e[\"unit_key\"]][\"property\"], e[\"varname\"], e[\"samplegroup_key\"]): Indicator(\n",
    "        id = get_indicator_identifier(UNIT_CONVERSION[e[\"unit_key\"]][\"property\"], e[\"varname\"], e[\"samplegroup_key\"]),\n",
    "        unique_name = get_indicator_identifier(UNIT_CONVERSION[e[\"unit_key\"]][\"property\"], e[\"varname\"], e[\"samplegroup_key\"]),\n",
    "        name = get_indicator_identifier(UNIT_CONVERSION[e[\"unit_key\"]][\"property\"], e[\"varname\"], e[\"samplegroup_key\"]),\n",
    "        label = get_indicator_identifier(UNIT_CONVERSION[e[\"unit_key\"]][\"property\"], e[\"varname\"], e[\"samplegroup_key\"]),\n",
    "        indicator_type = IndicatorType.exposuremarker,\n",
    "        varname = e[\"varname\"],\n",
    "        property = UNIT_CONVERSION[e[\"unit_key\"]][\"property\"],\n",
    "        quantity_kind = UNIT_CONVERSION[e[\"unit_key\"]][\"quantity_kind\"],\n",
    "        matrix = e[\"samplegroup_key\"],\n",
    "        relevant_observable_entity_types = [ObservableEntityType.person, ObservableEntityType.sample]\n",
    "    )\n",
    "    for e in dl_prop\n",
    "#    if e[\"unit_key\"] not in [\"ng/filter\", \"pg BEQ/g\", \"pmol/g globin\"]\n",
    "}\n",
    "print(len(dl_prop))\n",
    "print(len(set([get_indicator_identifier(UNIT_CONVERSION[p[\"unit_key\"]][\"property\"], p[\"varname\"], p[\"samplegroup_key\"]) for p in dl_prop])))\n",
    "print(len([p for p in dl_prop if p[\"unit_key\"] not in [\"ng/filter\", \"pg BEQ/g\", \"pmol/g globin\"]]))\n",
    "print(len(indicator_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get core <> base relations from forYaml_sampleobsbase_sampleobscore.csv\n",
    "df_base_core_relations = pd.read_csv(\"../source_tables/indicator_input/forYaml_sampleobsbase_sampleobscore.csv\", sep=';', encoding='utf-8')\n",
    "dl_base_core_relations = df_base_core_relations.replace({np.nan:None}).to_dict(orient=\"records\")\n",
    "dd_base_core_relations = {base_translation_dict[d]:[br for br in dl_base_core_relations if br[\"sampleobsbase_id\"]==d] for d in base_translation_dict.keys()}\n",
    "dd_core_base_relations = {core_translation_dict[c]:[br for br in dl_base_core_relations if br[\"sampleobscore_id\"]==c] for c in core_translation_dict.keys()}\n",
    "print(list(set([bcr[\"linktype\"] for bcr in dl_base_core_relations])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create BioChemEntity objects for base groups defined as core\n",
    "dl_base_core_group_relations = [bcr for bcr in dl_base_core_relations if bcr[\"linktype\"] == \"group_contains\"]\n",
    "core_group_relation_ids = list(set([bcr[\"sampleobscore_id\"] for bcr in dl_base_core_group_relations]))\n",
    "core_group_relation_keys = [dd_core[core_translation_dict[sampleobscore_id]][\"varname\"] for sampleobscore_id in core_group_relation_ids]\n",
    "\n",
    "print(f\"{len(core_group_relation_ids)} core groups being added to biochementity_dict\")\n",
    "\n",
    "for sampleobscore_id in core_group_relation_ids:\n",
    "    core = dd_core[core_translation_dict[sampleobscore_id]]\n",
    "    linked_base_ids = [bcr[\"sampleobsbase_id\"] for bcr in dl_base_core_relations if bcr[\"sampleobscore_id\"] == sampleobscore_id and bcr[\"linktype\"] == \"group_contains\"]\n",
    "    if core[\"varname\"] in biochementity_dict.keys():\n",
    "        print(f\"{core['varname']} already exists in biochementity_dict\")\n",
    "    else:\n",
    "        biochementity_dict[core[\"varname\"]] = BioChemEntity(\n",
    "            id = core[\"varname\"],\n",
    "            unique_name = core[\"varname\"],\n",
    "            name = core[\"name_en\"],\n",
    "            label = core[\"label_en\"],\n",
    "            translations = [\n",
    "                Translation(property_name=\"name\", language=\"nl-be\", translated_value=core[\"name_nl\"]),\n",
    "                Translation(property_name=\"label\", language=\"nl-be\", translated_value=core[\"label_nl\"]),\n",
    "            ],\n",
    "            biochementity_links=[\n",
    "                BioChemEntityLink(biochementity_linktype=BioChemEntityLinkType.group_contains, biochementity=biochementity_dict[base_translation_dict[base_id]].id) for base_id in linked_base_ids\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get effect marker, their grouping and BioChemEntity relation from effectmarkersandprop.csv\n",
    "df_effectmarkers = pd.read_csv(\"../source_tables/indicator_input/effectmarkersandprop.csv\", sep=';', encoding='utf-8')\n",
    "dl_effectmarkers = df_effectmarkers.replace({np.nan:None}).to_dict(orient=\"records\")\n",
    "dd_effectmarkers = {k:[em for em in dl_effectmarkers if \"|\".join([em[\"varname\"], em[\"samplegroup_key\"]])==k] for k in set([\"|\".join([emk[\"varname\"], emk[\"samplegroup_key\"]]) for emk in dl_effectmarkers])}\n",
    "print(len(set([\"|\".join([em[\"varname\"], em[\"samplegroup_key\"]]) for em in dl_effectmarkers])))\n",
    "print(len(dl_effectmarkers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biochementity_keys = ['varname', 'vartype_key', 'name_en', 'linktype', 'chebi_id', 'inchikey_id']\n",
    "unique_effectmarker_biochementity_list = list(set([tuple(pv for pn,pv in em.items() if pn in biochementity_keys) for em in dl_effectmarkers]))\n",
    "print(len(unique_effectmarker_biochementity_list))\n",
    "em_biochementity_inclusion = [em for em in unique_effectmarker_biochementity_list if em[3]]\n",
    "print(len(em_biochementity_inclusion), set([em[1] for em in em_biochementity_inclusion]), set([em[3] for em in em_biochementity_inclusion]))\n",
    "em_biochementity_exclusion = [em for em in unique_effectmarker_biochementity_list if not em[3]]\n",
    "print(len(em_biochementity_exclusion), set([em[1] for em in em_biochementity_exclusion]), set([em[3] for em in em_biochementity_exclusion]))\n",
    "\n",
    "indicator_keys = ['varname', 'vartype_key', 'name_en', 'samplegroup_key', 'linktype', 'chebi_id', 'inchikey_id']\n",
    "unique_effectmarker_indicator_list = list(set([tuple(pv for pn,pv in em.items() if pn in indicator_keys) for em in dl_effectmarkers]))\n",
    "print(len(unique_effectmarker_indicator_list))\n",
    "print(len(dl_effectmarkers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inchi_to_base = {v['inchikey_id']:v[\"sampleobsbase_key\"] for v in dl_base_validation if v['validationID']==\"inchikey_id\"}\n",
    "chebi_to_base = {v['chebi_id']:v[\"sampleobsbase_key\"] for v in dl_base_validation if v['validationID']==\"chebi_id\"}\n",
    "\n",
    "for indicator_key in indicator_dict.keys():\n",
    "    if indicator_key in dd_effectmarkers.keys():\n",
    "        indicator_dict[indicator_key].indicator_type = IndicatorType.effectmarker\n",
    "        for em in dd_effectmarkers[indicator_key]:\n",
    "            if em[\"linktype\"] is None:\n",
    "                if len(indicator_dict[indicator_key].biochementity_links):\n",
    "                    print(indicator_key, indicator_dict[indicator_key].biochementity_links)\n",
    "            else:\n",
    "                em_done = False\n",
    "                if em[\"chebi_id\"] and em[\"chebi_id\"] in chebi_to_base.keys():\n",
    "                    indicator_dict[indicator_key].biochementity_links = [\n",
    "                        BioChemEntityLink(biochementity_linktype=BioChemEntityLinkType.exact_match, biochementity=biochementity_dict[chebi_to_base[em[\"chebi_id\"]]].id)\n",
    "                    ]\n",
    "                elif em[\"inchikey_id\"] and em[\"inchikey_id\"] in inchi_to_base.keys():\n",
    "                    indicator_dict[indicator_key].biochementity_links = [\n",
    "                        BioChemEntityLink(biochementity_linktype=BioChemEntityLinkType.exact_match, biochementity=biochementity_dict[inchi_to_base[em[\"inchikey_id\"]]].id)\n",
    "                    ]\n",
    "    elif indicator_dict[indicator_key].varname in core_group_relation_keys:\n",
    "        indicator_dict[indicator_key].biochementity_links = [\n",
    "            BioChemEntityLink(biochementity_linktype=BioChemEntityLinkType.exact_match, biochementity=biochementity_dict[indicator_dict[indicator_key].varname].id)\n",
    "        ]\n",
    "    else:\n",
    "        indicator_dict[indicator_key].biochementity_links = [\n",
    "            BioChemEntityLink(biochementity_linktype=get_linktype(cbr['linktype']), biochementity=biochementity_dict[base_translation_dict[cbr['sampleobsbase_id']]].id)\n",
    "            for cbr in dd_core_base_relations[indicator_dict[indicator_key].varname]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forYaml_sampleobscore_category.csv > add grouping_id_list in Indicator dict\n",
    "dl_core_cat = pd.read_csv(\"../source_tables/indicator_input/forYaml_sampleobscore_category.csv\", sep=';', encoding='utf-8').replace({np.nan:None}).to_dict(orient=\"records\")\n",
    "for core_cat in dl_core_cat:\n",
    "    for indicator in [i for i in indicator_dict.values() if i.unique_name.startswith(core_translation_dict[core_cat[\"sampleobscore_id\"]] + \"|\")]:\n",
    "        indicator.grouping_id_list = list(set(indicator.grouping_id_list + [core_cat['category_key']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get variable data from PARC codebook v2.3\n",
    "parc_codebook_v23_dict = {k:v.replace({np.nan:None}).to_dict(orient=\"records\") for k,v in pd.read_excel(\"../source_tables/PARC/BasicCodebook_v2.3.xlsx\", sheet_name=None).items()}\n",
    "tab_names = parc_codebook_v23_dict.keys()\n",
    "tab_study_entity_translation = {'SAMPLE': \"Sample\", 'TIMEPOINT': \"Timepoint\", 'SUBJECTUNIQUE': \"Person\", 'SUBJECTTIMEPOINT': \"Person\", 'SAMPLETIMEPOINT': \"Sample\", \"ANALYTICALINFO\": \"SamplingResult\"}\n",
    "\n",
    "codebook_variable_list = []\n",
    "for k in tab_study_entity_translation.keys():\n",
    "    for v in parc_codebook_v23_dict[k]:\n",
    "        v[\"StudyEntityType\"] = tab_study_entity_translation[k]\n",
    "        if v[\"Varname\"] not in ['id_subject', 'matrix', 'id_sample', 'id_timepoint']:\n",
    "            codebook_variable_list.append(v)\n",
    "        elif (v[\"Varname\"], k) in [('id_subject', 'SUBJECTUNIQUE'), ('matrix', 'SAMPLE'), ('id_sample', 'SAMPLE'), ('id_timepoint', 'TIMEPOINT')]:\n",
    "            codebook_variable_list.append(v)\n",
    "print(len(codebook_variable_list) - len({v[\"Varname\"] for v in codebook_variable_list}))\n",
    "\n",
    "varname_to_study_entity_type_dict = {vn:[v[\"StudyEntityType\"] for v in codebook_variable_list if v[\"Varname\"]==vn] for vn in set([v[\"Varname\"] for v in codebook_variable_list])}\n",
    "print({k for k,v in varname_to_study_entity_type_dict.items() if len(v) > 1})\n",
    "\n",
    "VARNAME_CONDITIONAL_DICT = {v[\"Varname\"]:v[\"Conditional\"] for v in codebook_variable_list if v[\"Conditional\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forYaml_sampleobscore_sampleobsprop.csv\n",
    "# - create ObservableProperty objects, one for each Indicator, adding: unit, etc, ...\n",
    "observable_property_dict = {\n",
    "    get_indicator_identifier(UNIT_CONVERSION[e[\"unit_key\"]][\"property\"], e[\"varname\"], e[\"samplegroup_key\"]): ObservableProperty(\n",
    "        id = get_indicator_identifier(UNIT_CONVERSION[e[\"unit_key\"]][\"property\"], e[\"varname\"], e[\"samplegroup_key\"]),\n",
    "        unique_name = get_indicator_identifier(UNIT_CONVERSION[e[\"unit_key\"]][\"property\"], e[\"varname\"], e[\"samplegroup_key\"]),\n",
    "        name = \" concentration in \".join([e[\"varname\"], e[\"samplegroup_key\"]]),\n",
    "        label = \" concentration in \".join([e[\"varname\"], e[\"samplegroup_key\"]]),\n",
    "        categorical=False, multivalued=False,\n",
    "        default_required=False, default_significantdecimals=e[\"significantdecimals\"], default_zeroallowed=bool(e[\"zeroallowed\"]),\n",
    "        value_type = dd_core[e[\"varname\"]][\"datatype_key\"],\n",
    "        default_unit = UNIT_CONVERSION[e[\"unit_key\"]][\"default_unit\"],\n",
    "        default_observation_result_type = ObservationResultType.calculation if dd_core[e[\"varname\"]][\"vartype_key\"]==\"derived\" else ObservationResultType.measurement,\n",
    "        relevant_observation_types = [ObservationType.sampling],\n",
    "        indicator=get_indicator_identifier(UNIT_CONVERSION[e[\"unit_key\"]][\"property\"], e[\"varname\"], e[\"samplegroup_key\"]),\n",
    "        calculation_designs = [\n",
    "            CalculationDesign(\n",
    "                calculation_name=\"*\",\n",
    "                calculation_implementation_as_json=json.dumps(CALCULATION_CONVERSION_DICT[e[\"formula\"]]),\n",
    "                calculation_implementation=get_calculation_implementation_from_dict(CALCULATION_CONVERSION_DICT[e[\"formula\"]])\n",
    "            )\n",
    "        ] if e[\"formula\"] else None,\n",
    "        validation_designs=[\n",
    "            ValidationDesign(conditional = VARNAME_CONDITIONAL_DICT[e[\"varname\"]])\n",
    "        ] if e[\"varname\"] in VARNAME_CONDITIONAL_DICT.keys() else None\n",
    "    )\n",
    "    for e in dl_prop\n",
    "#    if e[\"unit_key\"] not in [\"ng/filter\", \"pg BEQ/g\", \"pmol/g globin\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forYaml_sampleobsprop_statistics.csv > add constraint to ObservableProperty value_metadata (as field & value)\n",
    "dl_prop_stat = pd.read_csv(\"../source_tables/indicator_input/forYaml_sampleobsprop_statistics.csv\", sep=';', encoding='utf-8').replace({np.nan:None}).to_dict(orient=\"records\")\n",
    "\n",
    "# preliminary solution for forYaml_sampleobsprop_statistics.csv not containing units\n",
    "stats_id_dict = {\n",
    "    stats_id: list(set([get_indicator_identifier(UNIT_CONVERSION[e[\"unit_key\"]][\"property\"], e[\"varname\"], e[\"samplegroup_key\"]) for e in dl_prop if \"|\".join([e[\"varname\"], e[\"samplegroup_key\"]])==stats_id]))\n",
    "    for stats_id in set([\"|\".join([p[\"varname\"], p[\"samplegroup_key\"]]) for p in dl_prop_stat if p[\"varname\"] and p[\"samplegroup_key\"]])\n",
    "}\n",
    "\n",
    "for prop_stat in dl_prop_stat:\n",
    "    if prop_stat[\"varname\"] and prop_stat[\"samplegroup_key\"] and prop_stat[\"statswhat\"] and prop_stat[\"statsvalue\"]:\n",
    "        for indicator_id in stats_id_dict[\"|\".join([prop_stat[\"varname\"], prop_stat[\"samplegroup_key\"]])]:\n",
    "            observable_property_dict[indicator_id].value_metadata.append(ObservablePropertyMetadataElement(\n",
    "                field=prop_stat[\"statswhat\"],\n",
    "                value=str(prop_stat[\"statsvalue\"])\n",
    "            ))\n",
    "            observable_property_dict[indicator_id].value_metadata.append(ObservablePropertyMetadataElement(\n",
    "                field=prop_stat[\"statswhat\"]+\"_provenance\",\n",
    "                value=json.dumps({\n",
    "                \"source\": prop_stat[\"statsprovenance_source\"],\n",
    "                \"source_matrix\": prop_stat[\"sampletype_key\"], \n",
    "                \"value\": prop_stat[\"statsvalue\"],\n",
    "                \"contact\": prop_stat[\"statsprovenance_who\"],\n",
    "                \"source_detail\": prop_stat[\"statsprovenance_source_detail\"],\n",
    "                \"source_info\": prop_stat[\"statsprovenance_source_info\"], \n",
    "            })))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_dumper.dump({\"biochementities\": [v for v in biochementity_dict.values() if v]}, \"../extract/BioChemEntityList_data.yaml\")\n",
    "yaml_dumper.dump({\"indicators\": [v for v in indicator_dict.values() if v]}, \"../extract/IndicatorList_data.yaml\")\n",
    "yaml_dumper.dump({\"observable_properties\": [v for v in observable_property_dict.values() if v]}, \"../extract/ObservablePropertyList_data.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stakeholder and the IDs of their sampleobsprops from forYaml_sampleobsprop_stakeholder.csv\n",
    "dl_stakeholder_sampleobsprops = pd.read_csv(\"../source_tables/indicator_input/forYaml_sampleobsprop_stakeholder.csv\", sep=';', encoding='utf-8').replace({np.nan:None}).to_dict(orient=\"records\")\n",
    "\n",
    "dd_stakeholder_sampleobsprops = {k:list({get_indicator_identifier_from_sampleobsprop_id(r[\"sampleobsprop_id\"]) for r in dl_stakeholder_sampleobsprops if r[\"stakeholder_key\"]==k}) for k in {r[\"stakeholder_key\"] for r in dl_stakeholder_sampleobsprops}}\n",
    "dd_project_sampleobsprops = {k:list({get_indicator_identifier_from_sampleobsprop_id(r[\"sampleobsprop_id\"]) for r in dl_stakeholder_sampleobsprops if r[\"projectname\"]==k}) for k in {r[\"projectname\"] for r in dl_stakeholder_sampleobsprops}}\n",
    "\n",
    "for k in dd_stakeholder_sampleobsprops.keys():\n",
    "    print(k, len(dd_stakeholder_sampleobsprops[k]))\n",
    "    yaml_dumper.dump({\"indicators\": [{\"id\": v} for v in dd_stakeholder_sampleobsprops[k]]}, f\"../extract/Stakeholder_{k}_IndicatorIdList.yaml\")\n",
    "\n",
    "for k in dd_project_sampleobsprops.keys():\n",
    "    print(k, len(dd_project_sampleobsprops[k]))\n",
    "    yaml_dumper.dump({\"indicators\": [{\"id\": v} for v in dd_project_sampleobsprops[k]]}, f\"../extract/Project_{k}_IndicatorIdList.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
