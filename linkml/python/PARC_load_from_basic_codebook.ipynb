{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from linkml_runtime.dumpers import json_dumper, yaml_dumper\n",
    "\n",
    "import uuid\n",
    "from numpy import sort\n",
    "\n",
    "import peh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook_path = Path(\"../source_tables/PARC/BasicCodebook_v2.3.xlsx\")\n",
    "data_path = Path(\"../source_tables/PARC/ExData_BasicCodebook_v2.3.xlsx\")\n",
    "yaml_file_path = Path(\"../project_examples/PARC/parc.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pd.read_excel(data_path, sheet_name=None)\n",
    "for k, v in data_dict.items():\n",
    "    data_dict[k] = v.replace(np.nan, None)\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities\n",
    "The entities we will use for this data are:\n",
    "- EntityList\n",
    "    - StudyEntity\n",
    "        - Study (example-study) \n",
    "        - Person\n",
    "        - Sample\n",
    "        - PersonGroup\n",
    "        - SampleCollection (equivalent to one of the tabs)\n",
    "        - Timepoint\n",
    "\n",
    "Additionally, we want to extract properties for these entities from the BasicCodebook, but that's for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [x for x in dir(peh) if \"sampl\" in x.lower()]\n",
    "print(s)\n",
    "print(dir(peh.SamplingResult))\n",
    "print(dir(peh.SamplingObservation))\n",
    "print(peh.SamplingResult())\n",
    "print(peh.SamplingObservation(id=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entitylist = peh.EntityList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_sheet = data_dict[\"STUDYINFO\"]\n",
    "study = peh.Study(id=study_sheet.iloc[11][1])\n",
    "entitylist.studies = [study]\n",
    "study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints_sheet = data_dict[\"TIMEPOINT\"]\n",
    "\n",
    "timepoints = {}\n",
    "for i, row in timepoints_sheet.iterrows():\n",
    "    tp = peh.Timepoint(id=peh.TimepointId(row[\"id_timepoint\"]))\n",
    "    timepoints[row[\"id_timepoint\"]] = tp\n",
    "entitylist.timepoints = timepoints\n",
    "study.timepoint_id_list = [peh.TimepointId(x) for x in timepoints.keys()]\n",
    "timepoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE\n",
    "sample_sheet = data_dict[\"SAMPLE\"]\n",
    "\n",
    "# where to save these?\n",
    "samples = []\n",
    "\n",
    "# SamplingObservation > SamplingResult > ObservedValue\n",
    "sampling_design = peh.SamplingDesign()\n",
    "to_ignore = {\"id_sample\", \"id_subject\", \"id_timepoint\"}\n",
    "special_fields = {\"chol\", \"trigl\", \"lipid\", \"lipid_enz\", \"crt\", \"sg\", \"osm\", \"density\", \"lipid_enz_harm\"}\n",
    "for _, row in sample_sheet.iterrows():\n",
    "    sample = peh.Sample(id=peh.SampleId(row[\"id_sample\"]))\n",
    "    samples.append(sample)\n",
    "    meta_values = []\n",
    "    sample_values = []\n",
    "    obs = []\n",
    "    for idx, val in row.items():\n",
    "        if idx not in to_ignore:\n",
    "            if idx not in special_fields:\n",
    "                meta_values.append(peh.ObservedValue(observable_entity=sample.id, value=val, observable_property=idx))\n",
    "            else:\n",
    "                sample_values.append(peh.ObservedValue(observable_entity=sample.id, value=val, observable_property=idx))\n",
    "\n",
    "    meta_res = peh.SamplingResult(observed_values=meta_values)\n",
    "    sampling_res = peh.SamplingResult(observed_values=sample_values)\n",
    "    obs.append(peh.SamplingObservation(id=peh.SamplingObservationId(uuid.uuid4()), observation_result=sampling_res, observation_design=sampling_design, observation_type=peh.ObservationType.sampling))\n",
    "    obs.append(peh.SamplingObservation(id=peh.SamplingObservationId(uuid.uuid4()), observation_result=meta_res, observation_design=sampling_design, observation_type=peh.ObservationType.metadata))\n",
    "    timepoints[row[\"id_timepoint\"]].observations.append(obs)\n",
    "               \n",
    "                \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_unique_sheet = data_dict[\"SUBJECTUNIQUE\"]\n",
    "subject_design = peh.QuestionnaireDesign()\n",
    "to_ignore = {\"id_subject\", \"id_participant\"}\n",
    "\n",
    "# where to save these\n",
    "subjects = []\n",
    "\n",
    "# link persons to each other\n",
    "subject_groups = {i: peh.PersonGroup(i) for i in set(subject_unique_sheet[\"id_participant\"].values)}\n",
    "\n",
    "for _, row in subject_unique_sheet.iterrows():\n",
    "    person = peh.Person(id=peh.PersonId(row[\"id_subject\"]))\n",
    "    subjects.append(person)\n",
    "    \n",
    "    values = []\n",
    "    obs = []\n",
    "    for idx, val in row.items():\n",
    "        if idx not in to_ignore:\n",
    "            values.append(peh.ObservedValue(observable_entity=person.id, value=val, observable_property=idx))\n",
    "    subject_groups[row[\"id_participant\"]].study_entity_links.append(peh.StudyEntityLink(study_entity=peh.StudyEntityId(row[\"id_participant\"]), linktype=peh.LinkType.is_part_of))\n",
    "    res = peh.QuestionnaireResult(observed_values=values)\n",
    "    obs.append(peh.QuestionnaireObservation(id=peh.QuestionnaireObservationId(uuid.uuid4()), observation_result=res, observation_design=subject_design, observation_type=peh.ObservationType.questionnaire))\n",
    "    # no timepoints linked, so we use the first one. Assumes these are somehow alphabetically or numerically sortable\n",
    "    timepoints[sort(list(timepoints.keys()))[0]].observations.append(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_timepoint_sheet = data_dict[\"SUBJECTTIMEPOINT\"]\n",
    "to_ignore = {\"id_subject\", \"id_timepoint\"}\n",
    "\n",
    "for _, row in subject_timepoint_sheet.iterrows():\n",
    "    values = []\n",
    "    obs = []\n",
    "    for idx, val in row.items():\n",
    "        if idx not in to_ignore:\n",
    "            values.append(peh.ObservedValue(observable_entity=person.id, value=val, observable_property=idx))\n",
    "    res = peh.QuestionnaireResult(observed_values=values)\n",
    "    obs.append(peh.QuestionnaireObservation(id=peh.QuestionnaireObservationId(uuid.uuid4()), observation_result=res, observation_design=subject_design, observation_type=peh.ObservationType.questionnaire))\n",
    "    # no timepoints linked, so we use the first one. Assumes these are somehow alphabetically or numerically sortable\n",
    "    timepoints[row[\"id_timepoint\"]].observations.append(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampletimepoint_sheets = {k: v for k, v in data_dict.items() if str(k).startswith(\"SAMPLETIMEPOINT\")}\n",
    "\n",
    "timepoints_lookup = sample_sheet[[\"id_sample\", \"id_timepoint\"]]\n",
    "\n",
    "for k, v in sampletimepoint_sheets.items():\n",
    "    # SamplingObservation > SamplingResult > ObservedValue\n",
    "    sheet = v.merge(timepoints_lookup, on=\"id_sample\")\n",
    "    sampling_design = peh.SamplingDesign()\n",
    "    orig = {i[:-4] for i in sheet.columns if i.endswith(\"_lod\") or i.endswith(\"_loq\")}\n",
    "    markers = orig - special_fields\n",
    "    to_ignore = {\"id_sample\"}\n",
    "    for _, row in sheet.iterrows():\n",
    "        values = []\n",
    "        obs = []\n",
    "        for m in markers:\n",
    "            values.append(peh.ObservedValue(observable_entity=peh.SampleId(row[\"id_sample\"]), value=row[str(m)], observable_property=str(m),\n",
    "                                            quality_data=[peh.QualityData(quality_context_key=\"lod\", quality_value=row[str(m) + \"_lod\"]),\n",
    "                                                          peh.QualityData(quality_context_key=\"loq\", quality_value=row[str(m) + \"_loq\"])]\n",
    "                                            ))\n",
    "\n",
    "        sampling_res = peh.SamplingResult(observed_values=values)\n",
    "        obs.append(peh.SamplingObservation(id=peh.SamplingObservationId(uuid.uuid4()), observation_result=sampling_res, observation_design=sampling_design, observation_type=peh.ObservationType.sampling))\n",
    "        \n",
    "        timepoints[row[\"id_timepoint\"]].observations.append(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linkml_runtime.dumpers import yaml_dumper\n",
    "\n",
    "\n",
    "yaml_dumper.dump(entitylist, Path(\"out/PARC/data.yaml\"))\n",
    "# list all samples\n",
    "yaml_dumper.dump(samples, Path(\"out/PARC/samples.yaml\"))\n",
    "# list all subjects\n",
    "yaml_dumper.dump(subjects, Path(\"out/PARC/persons.yaml\"))\n",
    "yaml_dumper.dump(list(subject_groups.values()), Path(\"out/PARC/person_groups.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linkml_runtime.dumpers import json_dumper\n",
    "cwd = Path.cwd()\n",
    "\n",
    "json_dumper.dump(entitylist, cwd / \"out/PARC/data.jsonld\", contexts=str(cwd / \"out/peh.jsonld\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
